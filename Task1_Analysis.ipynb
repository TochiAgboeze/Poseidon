{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Catboost\n",
        "! pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbQGh5sYEnjh",
        "outputId": "4018734d-586d-4395-c6da-3cbf382b6ce0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9MEwPmpMsXj5"
      },
      "outputs": [],
      "source": [
        "# Load Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LkZf83Xmy1UE"
      },
      "outputs": [],
      "source": [
        "# Define custom function which returns single output as metric score\n",
        "\n",
        "def calculate_smape(actual, predicted) -> float:\n",
        "\n",
        "    # Convert actual and predicted to numpy\n",
        "    # array data type if not already\n",
        "    if not all([isinstance(actual, np.ndarray),\n",
        "                isinstance(predicted, np.ndarray)]):\n",
        "        actual, predicted = np.array(actual),\n",
        "        np.array(predicted)\n",
        "\n",
        "    return round(\n",
        "        np.mean(\n",
        "            np.abs(predicted - actual) /\n",
        "            ((np.abs(predicted) + np.abs(actual))/2)\n",
        "        )*100, 2\n",
        "    )\n",
        "\n",
        "\n",
        "#make scorer from custome function\n",
        "smape_scorer = make_scorer(calculate_smape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NMkSXmVipbXi"
      },
      "outputs": [],
      "source": [
        "# Define custom function which returns single output as metric score\n",
        "def smape(A, F):\n",
        "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GYHt7MiomnK"
      },
      "source": [
        "## **Window Frames method with different models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pPLJykoes0Hp"
      },
      "outputs": [],
      "source": [
        "# Function to Split data to window frames\n",
        "\n",
        "def df_to_X_y(df, window_size=3):\n",
        "  df_as_np=df.to_numpy()\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(len(df_as_np)-window_size):\n",
        "    row = df_as_np[i:i+window_size]\n",
        "    X.append(row)\n",
        "    label = df_as_np[i+window_size]\n",
        "    y.append(label)\n",
        "  return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Models\n",
        "\n",
        "model_names = [\n",
        "    \"Decision Tree\", \"Random Forest\", \"Linear Regression\", \"Gradient Boosting\", \"Neural Network\",\n",
        "    \"XGBoost\", \"LightGBM\", \"CatBoost\"\n",
        "]\n",
        "models = [\n",
        "    DecisionTreeRegressor(), RandomForestRegressor(), LinearRegression(), GradientBoostingRegressor(), MLPRegressor(),\n",
        "    XGBRegressor(), LGBMRegressor(verbose=-1), CatBoostRegressor(verbose=0)\n",
        "]\n"
      ],
      "metadata": {
        "id": "p7BH0qfMDvi3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nQRaWTxaVFT",
        "outputId": "f4e32420-618c-49de-cafd-3c938e96faeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree SMAPE SCore:  0.17204508212063682\n",
            "Random Forest SMAPE SCore:  0.15550039920179773\n",
            "Linear Regression SMAPE SCore:  0.13859446406155654\n",
            "Gradient Boosting SMAPE SCore:  0.13920713162429618\n",
            "Neural Network SMAPE SCore:  6.982312583162025\n",
            "XGBoost SMAPE SCore:  0.16251925820813873\n",
            "LightGBM SMAPE SCore:  0.15663260385277206\n",
            "CatBoost SMAPE SCore:  0.15008457924327337\n"
          ]
        }
      ],
      "source": [
        "for model_name, model in zip(model_names, models):\n",
        "\n",
        "  Pred=[]\n",
        "  actuals=[]\n",
        "  # Loop through each dataset\n",
        "  for i in os.listdir(\"/content/drive/MyDrive/filtered\"):\n",
        "    path=\"/content/drive/MyDrive/filtered/\"+i\n",
        "    # Read the dataset\n",
        "    df=pd.read_csv(path)\n",
        "    df=df.iloc[:-1,:]\n",
        "    df.ffill(inplace=True)\n",
        "    y_test=list(df.iloc[-26:, :][\"Levels\"].values)\n",
        "    for yss in y_test:\n",
        "      actuals.append(yss)\n",
        "    df=df.iloc[:-26,:]\n",
        "    # Split to window frames of 3 and train model\n",
        "    X,y= df_to_X_y(df[\"Levels\"], window_size=3)\n",
        "    model.fit(X, y)\n",
        "    lst=list(df[\"Levels\"].tail(3).values)\n",
        "\n",
        "    # Model Prediction for testing\n",
        "    for ii in range(26):\n",
        "            result=model.predict([lst])\n",
        "            Pred.append(round(result[0], 2))\n",
        "            lst.pop(0)\n",
        "            lst.append(result[0])\n",
        "\n",
        "  # Getting SMAPE Scores for models\n",
        "  test=pd.DataFrame({\"Predictions\":Pred, \"Actuals\":actuals}).dropna()\n",
        "\n",
        "  A = test[\"Actuals\"]\n",
        "  F = test[\"Predictions\"]\n",
        "  print(model_name+\" SMAPE SCore: \", smape(A, F))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dl-KrrexDLk"
      },
      "source": [
        "## **Feature Extraction Technique with different Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfFcIeRRxWQu",
        "outputId": "b6f93330-392b-4a50-a91f-6478201fe59d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree SMAPE SCore:  0.13657110222850494\n",
            "Random Forest SMAPE SCore:  0.12634429688212107\n",
            "Linear Regression SMAPE SCore:  0.17342492768150092\n",
            "Gradient Boosting SMAPE SCore:  0.12953045383309442\n",
            "Neural Network SMAPE SCore:  2.4405739496895755\n",
            "XGBoost SMAPE SCore:  0.13342506972787024\n",
            "LightGBM SMAPE SCore:  0.12082219218344961\n",
            "CatBoost SMAPE SCore:  0.13083925580895717\n"
          ]
        }
      ],
      "source": [
        "for model_name, model in zip(model_names, models):\n",
        "\n",
        "  Pred=[]\n",
        "  actuals=[]\n",
        "  # Loop through datasets\n",
        "  for i in os.listdir(\"/content/drive/MyDrive/filtered\"):\n",
        "    path=\"/content/drive/MyDrive/filtered/\"+i\n",
        "    # Read the dataset\n",
        "    df=pd.read_csv(path)\n",
        "    df=df.iloc[:-1,:]\n",
        "    df.ffill(inplace=True)\n",
        "    df[\"Date\"]=pd.to_datetime(df[\"Date\"], format=\"%d.%m.%Y %H:%M:%S   \")\n",
        "    df.sort_values(by=\"Date\", inplace=True)\n",
        "    # Feature Extraction\n",
        "    df[\"Day\"]=df[\"Date\"].dt.day\n",
        "    df[\"Dayofweek\"]=df[\"Date\"].dt.dayofweek\n",
        "    df[\"Month\"]=df[\"Date\"].dt.month\n",
        "    df[\"Year\"]=df[\"Date\"].dt.year\n",
        "    df[\"Quarter\"]=df[\"Date\"].dt.quarter\n",
        "    df[\"Week\"]=df[\"Date\"].dt.isocalendar().week\n",
        "    df=df.drop(\"Date\", axis=1)\n",
        "    # Split dataset to train and test\n",
        "    train=df.iloc[:-26,:]\n",
        "    test=df.iloc[-26:, :]\n",
        "    # Split dataset to dependent and independent features\n",
        "    X_train=train.drop(\"Levels\", axis=1)\n",
        "    y_train=train[\"Levels\"]\n",
        "    X_test=test.drop(\"Levels\", axis=1)\n",
        "    y_test=test[\"Levels\"]\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "    pred=model.predict(X_test)\n",
        "    # Make Predictions\n",
        "    for yss in y_test.values:\n",
        "      actuals.append(yss)\n",
        "    for yss in pred:\n",
        "      Pred.append(yss)\n",
        " # Test the models\n",
        "  test=pd.DataFrame({\"Predictions\":Pred, \"Actuals\":actuals}).dropna()\n",
        "\n",
        "  A = test[\"Actuals\"]\n",
        "  F = test[\"Predictions\"]\n",
        "  print(model_name+\" SMAPE SCore: \", smape(A, F))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJtFhC31pgA1"
      },
      "source": [
        "**Feature Extraction with Light GBM is the best performing methodology**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}